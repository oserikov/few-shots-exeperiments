{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "few shot experiments.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oserikov/few-shots-exeperiments/blob/master/few_shot_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi_PApVpZbns",
        "colab_type": "text"
      },
      "source": [
        "# experiments with the [paper](https://arxiv.org/pdf/1804.02063.pdf)\n",
        "\n",
        "paper title: Few-Shot Text Classification with Pre-Trained Word Embeddings and a Human in the Loop\n",
        "\n",
        "[paper code](https://github.com/katbailey/few-shot-text-classification/blob/master/Few-Shot-Text-Classification.ipynb)\n",
        "\n",
        "the cells that require involvement are marked with the gear ⚙️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VhKu-nNPzUb",
        "colab_type": "text"
      },
      "source": [
        "## preliminary set-up\n",
        "install and import modules, download some data\n",
        "\n",
        "⏳ took ~5 minutes for me"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfXVj3x1KuGM",
        "colab_type": "text"
      },
      "source": [
        "### install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqYYzCptzlXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67ee9cf6-216f-44bd-d02d-ee7673f97255"
      },
      "source": [
        "!pip install --progress-bar off --quiet gluonnlp | grep -v -P \"\\s*Building wheel\\.+done\\s*\"\n",
        "!pip install --progress-bar off --quiet --no-dependencies mxnet\n",
        "!pip install --progress-bar off --quiet --no-dependencies bert-embedding"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMYbw42pzmQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "827e4b9f-558f-47d5-c465-cf2fe4279b00"
      },
      "source": [
        "!git clone --quiet https://github.com/katbailey/few-shot-text-classification.git\n",
        "%cd -q few-shot-text-classification\n",
        "!git submodule --quiet init\n",
        "!git submodule --quiet update\n",
        "%cd -q SIF/\n",
        "!pip install --progress-bar off --quiet -r requirements.txt | grep -v -P \"\\s*Building wheel\\.+done\\s*\"\n",
        "%cd ../\n",
        "!sed -i -e \"s|iteritems()|items()|g\" SIF/src/data_io.py\n",
        "!sed -i -e \"s|xrange|range|g\" SIF/src/data_io.py\n",
        "!sed -i -e \"s|xrange|range|g\" SIF/src/SIF_embedding.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/few-shot-text-classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJpS3M8FK78P",
        "colab_type": "text"
      },
      "source": [
        "### imports\n",
        "(+ logging setup)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WywfzBIsNMpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import mxnet as mx\n",
        "from bert_embedding import BertEmbedding\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import en_core_web_sm\n",
        "# nlp = en_core_web_sm.load()\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy import displacy\n",
        "\n",
        "from IPython.display import HTML\n",
        "import logging\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from operator import itemgetter\n",
        "from itertools import cycle, islice\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "\n",
        "\n",
        "import utils\n",
        "import sif_embedding_wrapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2MldBok9JwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAVI8jlILEa7",
        "colab_type": "text"
      },
      "source": [
        "### download some pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj64RwJ5PfoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --quiet https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip -qq  wiki-news-300d-1M.vec.zip\n",
        "\n",
        "!wget --quiet http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -qq glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpN64ksDPZFp",
        "colab_type": "text"
      },
      "source": [
        "### download the paper-reproduction-data\n",
        "(downloader func definition)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaykuLDq3w0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_for_newsgroup_pair(category_pair):\n",
        "    newsgroups_train = fetch_20newsgroups(subset='train', categories=category_pair, remove=('headers', 'footers', 'quotes'))\n",
        "    docs = {}\n",
        "    for i,text in enumerate(newsgroups_train.data):\n",
        "        doc_id = str(i+1)\n",
        "        docs[doc_id] = {\n",
        "            \"text\": text.strip().strip('\"'),\n",
        "            \"category_ind\": newsgroups_train.target[i]\n",
        "        }\n",
        "    all_doc_ids = sorted(list(docs.keys()))\n",
        "    df = pd.DataFrame({\"text\": [docs[d][\"text\"] for d in all_doc_ids], \n",
        "                       \"category_ind\": [docs[d][\"category_ind\"] for d in all_doc_ids], \n",
        "                       \"doc_id\": [d for d in all_doc_ids]})\n",
        "    labels = []\n",
        "    for i in df[\"category_ind\"]:\n",
        "        parts = newsgroups_train.target_names[i].split(\".\")\n",
        "        if parts[-1] == \"misc\":\n",
        "            labels.append(parts[-2])\n",
        "        else:\n",
        "            labels.append(parts[-1])\n",
        "    df[\"label\"] = labels\n",
        "    categories = list(df[\"label\"].unique())\n",
        "    text_df = pd.DataFrame({\"doc_id\": df[\"doc_id\"], \"text\": df[\"text\"]})\n",
        "    truth_df = pd.DataFrame({\"doc_id\": df[\"doc_id\"], \"gt\": df[\"label\"]})\n",
        "    truth_dict = {str(rec[\"doc_id\"]): rec[\"gt\"] for rec in truth_df.to_dict(orient=\"records\")}\n",
        "    return text_df, truth_dict, categories\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXKS8OjLOXci",
        "colab_type": "text"
      },
      "source": [
        "## our experiments logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-xfEdzEQXq6",
        "colab_type": "text"
      },
      "source": [
        "### ⚙️download our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5U5YuBi36cI",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "3352a7a7-433a-47c1-9040-2545a38ca816"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "DATASET_FN = list(uploaded.keys())[0]  #\"clf_df.tsv\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9fd7ecec-c301-4495-84e5-88243fbc3d52\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9fd7ecec-c301-4495-84e5-88243fbc3d52\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving clf_df.tsv to clf_df.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKBHJx-rPnxf",
        "colab_type": "text"
      },
      "source": [
        "### various encoders definitions\n",
        "to be able compare them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MB8CKl0P2Fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNIVERSAL_ENCODER:\n",
        "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" \n",
        "\n",
        "    # \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "    def __init__(self):\n",
        "        print(\"BEFORE __init__\")\n",
        "        self.embed = hub.Module(self.module_url)\n",
        "        self.session = tf.Session()\n",
        "        self.session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "        print(\"AFTER __init__\")\n",
        "        \n",
        "    def embed_sentences(self, sentences_list):\n",
        "        print(\"BEFORE prediction\")\n",
        "        sentences_embeddings_ndarray = self.session.run(self.embed(sentences_list))\n",
        "        print(\"AFTER prediciton\")\n",
        "        sentences_embeddings_list = np.array(sentences_embeddings_ndarray).tolist()\n",
        "        return sentences_embeddings_list\n",
        "    \n",
        "    def embed_words(self, words_list):\n",
        "        return self.embed_sentences(words_list)\n",
        "\n",
        "\n",
        "class BERT_ENCODER:\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"BEFORE __init__\")\n",
        "        ctx = mx.cpu()  # mx.gpu(0)\n",
        "        self.bert_embedding = BertEmbedding(ctx=ctx)\n",
        "        print(\"AFTER __init__\")\n",
        "        \n",
        "    def embed_sentences(self, sentences_list):\n",
        "        print(\"BEFORE prediction\")\n",
        "        result = self.bert_embedding(sentences_list)\n",
        "        \n",
        "        print(\"AFTER prediciton\")\n",
        "        sentences_embeddings_list = [np.mean(elem[1], axis=0).tolist() for elem in result] \n",
        "        return sentences_embeddings_list\n",
        "\n",
        "\n",
        "class ELMO_ENCODER:\n",
        "    module_url = \"https://tfhub.dev/google/elmo/2\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"BEFORE __init__\")\n",
        "        self.embed = hub.Module(self.module_url)\n",
        "        self.session = tf.Session()\n",
        "        self.session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "        print(\"AFTER __init__\")\n",
        "        \n",
        "    def embed_sentences(self, sentences_list):\n",
        "        print(\"BEFORE prediction\")\n",
        "        sentences_embeddings_ndarray = self.session.run(self.embed(sentences_list, \n",
        "                                                                   signature=\"default\",\n",
        "                                                                   as_dict=True)[\"elmo\"])\n",
        "        \n",
        "        print(\"AFTER prediciton\")\n",
        "        \n",
        "        sentences_embeddings_list = [np.mean(elem, axis=0).tolist() for elem in sentences_embeddings_ndarray]\n",
        "        return sentences_embeddings_list\n",
        "\n",
        "\n",
        "class GLOVE_ENCODER:\n",
        "    def __init__(self):\n",
        "        print(\"BEFORE __init__\")\n",
        "        self.words, self.embs, self.weight4ind = sif_embedding_wrapper.load_embeddings(\n",
        "                                                    \"glove.6B.300d.txt\", \n",
        "                                                    \"SIF/auxiliary_data/enwiki_vocab_min200.txt\")\n",
        "        print(\"AFTER __init__\")\n",
        "        \n",
        "    def embed_sentences(self, sentences_list):\n",
        "        print(\"BEFORE prediction\")\n",
        "        result = sif_embedding_wrapper.sentences2vecs(sentences_list, \n",
        "                                                      self.embs, self.words, self.weight4ind)\n",
        "        \n",
        "        print(\"AFTER prediciton\")\n",
        "        # TODO\n",
        "        sentences_embeddings_list = result.tolist()\n",
        "        return sentences_embeddings_list\n",
        "\n",
        "    \n",
        "class W2V_ENCODER:\n",
        "    def __init__(self):\n",
        "        print(\"BEFORE __init__\")\n",
        "        self.words, self.embs, self.weight4ind = sif_embedding_wrapper.load_embeddings(\n",
        "                                                    \"wiki-news-300d-1M.vec\", \n",
        "                                                    \"SIF/auxiliary_data/enwiki_vocab_min200.txt\",\n",
        "                                                    word2vec=True)\n",
        "        print(\"AFTER __init__\")\n",
        "        \n",
        "    def embed_sentences(self, sentences_list):\n",
        "        print(\"BEFORE prediction\")\n",
        "        result = sif_embedding_wrapper.sentences2vecs(sentences_list, \n",
        "                                                      self.embs, self.words, self.weight4ind)\n",
        "        \n",
        "        print(\"AFTER prediciton\")\n",
        "        # TODO\n",
        "        sentences_embeddings_list = result.tolist()\n",
        "        return sentences_embeddings_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsHQG1UdO83z",
        "colab_type": "text"
      },
      "source": [
        "### ⚙️choose the encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZERMEMzLr24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "cellView": "form",
        "outputId": "3ae21697-1c7f-44af-9d93-94e24c7be53a"
      },
      "source": [
        "#@title choose the encoder\n",
        "#@markdown defaults to paper-default GloVe averaged over sentence tokens\n",
        "\n",
        "encoder = W2V_ENCODER() #@param [\"UNIVERSAL_ENCODER()\", \"BERT_ENCODER()\",\"ELMO_ENCODER()\",\"GLOVE_ENCODER()\",\"W2V_ENCODER()\"]{type:\"raw\"}\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEFORE __init__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/few-shot-text-classification/sif_embedding_wrapper.py:31: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
            "  word_embedding_df = pd.read_table(wordfile, delim_whitespace=True, index_col=0, header=None, quoting=csv.QUOTE_NONE, skiprows=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AFTER __init__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DqF2WbKUiU",
        "colab_type": "text"
      },
      "source": [
        "### initialize variables with our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHppjU4iDN8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(DATASET_FN, sep='\\t', header=0)\n",
        "df[\"doc_id\"] = np.arange(len(df))\n",
        "df[\"doc_id\"] = df[\"doc_id\"].astype(str)\n",
        "\n",
        "text_df = pd.DataFrame({\"doc_id\": df[\"doc_id\"], \"text\": df[\"text\"]})\n",
        "truth_df = pd.DataFrame({\"doc_id\": df[\"doc_id\"], \"gt\": df[\"label\"]})\n",
        "truth_dict = {str(rec[\"doc_id\"]): rec[\"gt\"] for rec in truth_df.to_dict(orient=\"records\")}\n",
        "\n",
        "gold_df = df[df[\"is_gold\"] == True]\n",
        "gold_dict = gold_df.groupby('label').agg({'doc_id':list}).to_dict()['doc_id']\n",
        "\n",
        "\n",
        "sentences = df[\"text\"].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frWjVH0MS2gM",
        "colab_type": "text"
      },
      "source": [
        "### ⚙️calculate embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVeRQLQnS4cz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "05415b0c-f1c5-4384-bc65-984dffcff847"
      },
      "source": [
        "# RERUN THIS EVERY TIME YOU CHANGE THE ENCODER\n",
        "\n",
        "sentences_embedded = encoder.embed_sentences(sentences)\n",
        "\n",
        "assert len(sentences) == len(sentences_embedded)\n",
        "\n",
        "df[\"vector\"] = pd.Series(list(sentences_embedded)) "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEFORE prediction\n",
            "AFTER prediciton\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L1pmwj8J_Yg",
        "colab_type": "text"
      },
      "source": [
        "### initialize variables with paper-reproduction-needed values\n",
        "(uncomment all the here to use)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPmSD4rzkeqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PAPER DATA USED TO REPRODUCE\n",
        "# df, truth_dict, categories = create_dataset_for_newsgroup_pair([\"rec.autos\",\"rec.sport.baseball\"]) # TODO\n",
        "# sentences = df[\"text\"]\n",
        "# sentences_embedded = encoder.embed_sentences(sentences)\n",
        "\n",
        "# assert len(sentences) == len(sentences_embedded)\n",
        "# gold_dict =  {\"autos\": [\"351\"], \"baseball\": [\"171\"]}\n",
        "# df[\"vector\"] = pd.Series(list(sentences_embedded))  # вот тут просто список списков эмбеддингов "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVDjI6XFKc1y",
        "colab_type": "text"
      },
      "source": [
        "### classification & evaluation logic\n",
        "classifier and accuracy functions defined\n",
        "\n",
        "(переписать бы, чот многобукаф и малодела)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLehYXoofj9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def auto_classify(docs, category_representators, min_text_length=80):\n",
        "    \n",
        "    # Exclude docs deemed too short to classify.\n",
        "    skip_prediction = list(df[df[\"text\"].map(len) < min_text_length].doc_id)\n",
        "    \n",
        "    categories = []\n",
        "    for repr_cat, repr_texts in category_representators.items():\n",
        "        categories.append(repr_cat)\n",
        "        skip_prediction.extend(repr_texts) # No need to predict manually labeled docs\n",
        "    \n",
        "    category_vecs = {}\n",
        "    for cat in categories:\n",
        "        vectors = np.asarray(list(docs.loc[docs['doc_id'].isin(category_representators[cat])].vector))\n",
        "        # category vector is the mean of the category representing vectors\n",
        "        category_vecs[cat] = np.mean(vectors, axis=0)\n",
        "\n",
        "    predictions = {}\n",
        "    for idx, row in docs.iterrows():\n",
        "        if row[\"doc_id\"] in skip_prediction:\n",
        "            continue        \n",
        "\n",
        "        winner = max(category_vecs, key = lambda v: cosine_similarity(np.array(row[\"vector\"]).reshape(1, -1), \n",
        "                                                                      np.array(category_vecs[v]).reshape(1, -1))\n",
        "                                                    .flatten()[0])\n",
        "        \n",
        "        predictions[row[\"doc_id\"]] = winner\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "def get_accuracy_score(predictions, truth_dict):\n",
        "    scores = []\n",
        "    for k,v in predictions.items():\n",
        "        if v == truth_dict[k]:\n",
        "            scores.append(1)\n",
        "        else:\n",
        "            scores.append(0)\n",
        "    if len(scores) == 0:\n",
        "        return 0.0\n",
        "    return sum(scores) / float(len(scores))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krzmM6a4KoT7",
        "colab_type": "text"
      },
      "source": [
        "### ⚙️classify then evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE7aOHTZegCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b8c8f5a-dab9-43cd-dfef-61cf3963a14d"
      },
      "source": [
        "preds = auto_classify(df,gold_dict, min_text_length=10)\n",
        "accuracy = get_accuracy_score(preds, truth_dict)\n",
        "print(f\"accuracy: {accuracy}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8777777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}